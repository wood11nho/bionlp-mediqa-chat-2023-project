{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5121695d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import evaluate\n",
    "import torch\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b2bfc71d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========== Load and Prepare Data ==========\n",
    "# Replace these paths if needed\n",
    "gold_path = \"../dataset/task_b+c/data/challenge_data/clinicalnlp_taskB_test1.csv\"\n",
    "system_output_path = \"../outputs/taskB_run1.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "034c1854",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read gold and system outputs\n",
    "df_gold = pd.read_csv(gold_path)\n",
    "df_pred = pd.read_csv(system_output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8c45cfbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename and align columns\n",
    "df_gold.rename(columns={\"note\": \"reference\", \"encounter_id\": \"EncounterID\"}, inplace=True)\n",
    "df_pred.rename(columns={\"SystemOutput\": \"prediction\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ed7a067f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename predicted column for consistency\n",
    "sys_df.rename(columns={text_column_sys: \"prediction\"}, inplace=True)\n",
    "gold_df.rename(columns={text_column_gold: \"reference\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8f4920fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge\n",
    "df = df_gold.merge(df_pred[[\"EncounterID\", \"prediction\"]], on=\"EncounterID\")\n",
    "references = df[\"reference\"].tolist()\n",
    "predictions = df[\"prediction\"].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fe5b579a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Loaded 40 prediction-reference pairs.\n"
     ]
    }
   ],
   "source": [
    "print(f\"‚úÖ Loaded {len(df)} prediction-reference pairs.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "51b164e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========== Metrics ==========\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f3f4b13b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Computing ROUGE...\n",
      "‚úÖ ROUGE computed.\n"
     ]
    }
   ],
   "source": [
    "# ROUGE\n",
    "print(\"üîç Computing ROUGE...\")\n",
    "rouge = evaluate.load(\"rouge\")\n",
    "rouge_scores = rouge.compute(predictions=predictions, references=references)\n",
    "print(\"‚úÖ ROUGE computed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0496db40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Computing BERTScore with bert-base-uncased on CPU...\n",
      "‚úÖ BERTScore computed.\n"
     ]
    }
   ],
   "source": [
    "# BERTScore (lighter model, CPU)\n",
    "print(\"üîç Computing BERTScore with bert-base-uncased on CPU...\")\n",
    "bertscore = evaluate.load(\"bertscore\", device=\"cpu\")\n",
    "bertscore_scores = bertscore.compute(\n",
    "    predictions=predictions,\n",
    "    references=references,\n",
    "    model_type=\"bert-base-uncased\",\n",
    "    device=\"cpu\"\n",
    ")\n",
    "print(\"‚úÖ BERTScore computed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fdfcf214",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Computing BLEURT (on CPU)...\n",
      "INFO:tensorflow:Reading checkpoint C:\\Users\\stoic\\.cache\\huggingface\\metrics\\bleurt\\BLEURT-20\\downloads\\extracted\\c55bb45fd2f4421f7460be96cbe7202b11151d877dd0e707e65c138aa101c4e7\\BLEURT-20.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reading checkpoint C:\\Users\\stoic\\.cache\\huggingface\\metrics\\bleurt\\BLEURT-20\\downloads\\extracted\\c55bb45fd2f4421f7460be96cbe7202b11151d877dd0e707e65c138aa101c4e7\\BLEURT-20.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Config file found, reading.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Config file found, reading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Will load checkpoint BLEURT-20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Will load checkpoint BLEURT-20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Loads full paths and checks that files exists.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Loads full paths and checks that files exists.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:... name:BLEURT-20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:... name:BLEURT-20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:... bert_config_file:bert_config.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:... bert_config_file:bert_config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:... max_seq_length:512\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:... max_seq_length:512\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:... vocab_file:None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:... vocab_file:None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:... do_lower_case:None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:... do_lower_case:None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:... sp_model:sent_piece\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:... sp_model:sent_piece\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:... dynamic_seq_length:True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:... dynamic_seq_length:True\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Creating BLEURT scorer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Creating BLEURT scorer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Creating SentencePiece tokenizer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Creating SentencePiece tokenizer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Creating SentencePiece tokenizer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Creating SentencePiece tokenizer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Will load model: C:\\Users\\stoic\\.cache\\huggingface\\metrics\\bleurt\\BLEURT-20\\downloads\\extracted\\c55bb45fd2f4421f7460be96cbe7202b11151d877dd0e707e65c138aa101c4e7\\BLEURT-20\\sent_piece.model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Will load model: C:\\Users\\stoic\\.cache\\huggingface\\metrics\\bleurt\\BLEURT-20\\downloads\\extracted\\c55bb45fd2f4421f7460be96cbe7202b11151d877dd0e707e65c138aa101c4e7\\BLEURT-20\\sent_piece.model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:SentencePiece tokenizer created.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:SentencePiece tokenizer created.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Creating Eager Mode predictor.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Creating Eager Mode predictor.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Loading model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Loading model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:BLEURT initialized.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:BLEURT initialized.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ BLEURT computed.\n"
     ]
    }
   ],
   "source": [
    "# BLEURT (on CPU)\n",
    "print(\"üîç Computing BLEURT (on CPU)...\")\n",
    "bleurt = evaluate.load(\"bleurt\", config_name=\"BLEURT-20\")\n",
    "bleurt_scores = bleurt.compute(predictions=predictions, references=references)\n",
    "print(\"‚úÖ BLEURT computed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d25b5bfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìä Evaluation Results:\n",
      "ROUGE-1: 0.1521\n",
      "ROUGE-2: 0.0519\n",
      "ROUGE-L: 0.1012\n",
      "ROUGE-Lsum: 0.1336\n",
      "\n",
      "BERTScore (bert-base-uncased):\n",
      "Precision: 0.5688\n",
      "Recall: 0.4428\n",
      "F1: 0.4969\n",
      "\n",
      "BLEURT:\n",
      "BLEURT score: 0.3082\n"
     ]
    }
   ],
   "source": [
    "# ========== Display Results ==========\n",
    "def average(metric_list):\n",
    "    return round(sum(metric_list) / len(metric_list), 4)\n",
    "\n",
    "print(\"\\nüìä Evaluation Results:\")\n",
    "print(\"ROUGE-1:\", round(rouge_scores[\"rouge1\"], 4))\n",
    "print(\"ROUGE-2:\", round(rouge_scores[\"rouge2\"], 4))\n",
    "print(\"ROUGE-L:\", round(rouge_scores[\"rougeL\"], 4))\n",
    "print(\"ROUGE-Lsum:\", round(rouge_scores[\"rougeLsum\"], 4))\n",
    "\n",
    "print(\"\\nBERTScore (bert-base-uncased):\")\n",
    "print(\"Precision:\", average(bertscore_scores[\"precision\"]))\n",
    "print(\"Recall:\", average(bertscore_scores[\"recall\"]))\n",
    "print(\"F1:\", average(bertscore_scores[\"f1\"]))\n",
    "\n",
    "print(\"\\nBLEURT:\")\n",
    "print(\"BLEURT score:\", average(bleurt_scores[\"scores\"]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llms_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
